{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from pandas.io.parsers import read_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Se definen los diccionarios de atributos que predeciran cada uno de los modelos que se implementaran\n",
    "\n",
    "training_specialists_settings = [\n",
    "    dict(\n",
    "        columns=(\n",
    "            'left_eye_center_x', 'left_eye_center_y',\n",
    "            'right_eye_center_x', 'right_eye_center_y',\n",
    "            ),\n",
    "        flip_indices=((0, 2), (1, 3)),\n",
    "        ),\n",
    "\n",
    "    dict(\n",
    "        columns=(\n",
    "            'nose_tip_x', 'nose_tip_y',\n",
    "            ),\n",
    "        flip_indices=(),\n",
    "        ),\n",
    "\n",
    "    dict(\n",
    "        columns=(\n",
    "            'mouth_left_corner_x', 'mouth_left_corner_y',\n",
    "            'mouth_right_corner_x', 'mouth_right_corner_y',\n",
    "            'mouth_center_top_lip_x', 'mouth_center_top_lip_y',\n",
    "            ),\n",
    "        flip_indices=((0, 2), (1, 3)),\n",
    "        ),\n",
    "\n",
    "    dict(\n",
    "        columns=(\n",
    "            'mouth_center_bottom_lip_x',\n",
    "            'mouth_center_bottom_lip_y',\n",
    "            ),\n",
    "        flip_indices=(),\n",
    "        ),\n",
    "\n",
    "    dict(\n",
    "        columns=(\n",
    "            'left_eye_inner_corner_x', 'left_eye_inner_corner_y',\n",
    "            'right_eye_inner_corner_x', 'right_eye_inner_corner_y',\n",
    "            'left_eye_outer_corner_x', 'left_eye_outer_corner_y',\n",
    "            'right_eye_outer_corner_x', 'right_eye_outer_corner_y',\n",
    "            ),\n",
    "        flip_indices=((0, 2), (1, 3), (4, 6), (5, 7)),\n",
    "        ),\n",
    "\n",
    "    dict(\n",
    "        columns=(\n",
    "            'left_eyebrow_inner_end_x', 'left_eyebrow_inner_end_y',\n",
    "            'right_eyebrow_inner_end_x', 'right_eyebrow_inner_end_y',\n",
    "            'left_eyebrow_outer_end_x', 'left_eyebrow_outer_end_y',\n",
    "            'right_eyebrow_outer_end_x', 'right_eyebrow_outer_end_y',\n",
    "            ),\n",
    "        flip_indices=((0, 2), (1, 3), (4, 6), (5, 7)),\n",
    "        ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Definimos metodo para cargar los archivos de entrenamiento para cada modelo a ser entrenado\n",
    "\n",
    "def loadTrainFile(cols=None):\n",
    "    df = read_csv(os.path.expanduser(train_file))\n",
    "    \n",
    "    # Es un solo campo separado por espacios hay que mostrarlo como array\n",
    "    df['Image'] = df['Image'].apply(lambda im: np.fromstring(im, sep=' '))\n",
    "    \n",
    "    # Filtramos los atributos especificos al modelo a ser entrenado\n",
    "    if cols:\n",
    "        df = df[list(cols) + ['Image']]\n",
    "                    \n",
    "    # Eliminamos las entradas que no tienen todos los atributos especificados\n",
    "    df = df.dropna() \n",
    "    \n",
    "    # Escalar los pixeles entre 0 y 1\n",
    "    X = np.vstack(df['Image'].values) / 255. \n",
    "    X = X.astype(np.float32)\n",
    "    \n",
    "    y = df[df.columns[:-1]].values\n",
    "    y = (y - 48) / 48\n",
    "    X, y = shuffle(X, y, random_state=42)  # ordenar aleatoriamente la data de entrenamiento\n",
    "    y = y.astype(np.float32)\n",
    "    \n",
    "    # Escalar en 2 dimensiones, los pixeles son de 96 x 96\n",
    "    X = X.reshape(-1, 96, 96, 1)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# El tipo de red neuronal a implementar es LeNet-5  (http://yann.lecun.com/exdb/lenet/)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Flatten, Dropout\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.callbacks import EarlyStopping, LearningRateScheduler\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def buildModel():\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    # Se agregan 3 capas convolucionales\n",
    "    model.add(Convolution2D(32,(3,3), input_shape=(96, 96, 1)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.1))\n",
    "    \n",
    "\n",
    "    model.add(Convolution2D(64, (2, 2)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Convolution2D(128, (2, 2)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    # Y dos capas densas\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1000, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1000, activation='relu'))\n",
    "    model.add(Dense(30))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Definimos metodo que usaremos para data augmentation, mediante el metodo de mirror image\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "class FlippedImageDataGenerator(ImageDataGenerator):\n",
    "    flip_indices = [(0, 2), (1, 3), (4, 8), (5, 9),\n",
    "                    (6, 10), (7, 11), (12, 16), (13, 17),\n",
    "                    (14, 18), (15, 19), (22, 24), (23, 25)]\n",
    "\n",
    "    def next(self):\n",
    "        X_batch, y_batch = super(FlippedImageDataGenerator, self).next()\n",
    "        batch_size = X_batch.shape[0]\n",
    "        indices = np.random.choice(batch_size, batch_size / 2, replace=False)\n",
    "        X_batch[indices] = X_batch[indices, :, :, ::-1]\n",
    "\n",
    "        if y_batch is not None:\n",
    "            y_batch[indices, ::2] = y_batch[indices, ::2] * -1\n",
    "\n",
    "            for a, b in self.flip_indices:\n",
    "                y_batch[indices, a], y_batch[indices, b] = (\n",
    "                    y_batch[indices, b], y_batch[indices, a]\n",
    "                )\n",
    "        print(X_batch.shape)\n",
    "        return X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Se define metodo que entrena los modelos especializados o training specialists\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import SGD\n",
    "from keras.models import model_from_json\n",
    "from collections import OrderedDict\n",
    "\n",
    "def normalFit():\n",
    "    start = 0.03\n",
    "    stop = 0.001\n",
    "    nb_epoch = 100\n",
    "    learning_rate = np.linspace(start, stop, nb_epoch)\n",
    "    \n",
    "    X, y = loadTrainFile()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.2, random_state=42)\n",
    "    model = model_from_json(net.to_json())\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    \n",
    "    change_lr = LearningRateScheduler(lambda epoch: float(learning_rate[epoch]))\n",
    "    early_stop = EarlyStopping(patience=100)\n",
    "    flipGen = FlippedImageDataGenerator()\n",
    "         \n",
    "    model.fit_generator(flipGen.flow(X_train, y_train),\n",
    "                                steps_per_epoch=X_train.shape[0],\n",
    "                                epochs=nb_epoch,\n",
    "                                validation_data=(X_test, y_test),\n",
    "                                callbacks=[change_lr, early_stop])        \n",
    "\n",
    "\n",
    "def fitTrainingSpecialists():\n",
    "    train_specialists = OrderedDict()\n",
    "    start = 0.03\n",
    "    stop = 0.001\n",
    "    nb_epoch = 100\n",
    "    learning_rate = np.linspace(start, stop, nb_epoch)\n",
    "    \n",
    "    for setting in training_specialists_settings:\n",
    "\n",
    "        # Se extraen las columnas especificas para cada modelo y se divide la data en set de entrenamiento\n",
    "        # y set de prueba\n",
    "        train_columns = setting['columns']\n",
    "        X, y = loadTrainFile(cols=train_columns)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        # Se utiliza el modelo definido previamente\n",
    "        train_specialist = model_from_json(net.to_json())\n",
    "        \n",
    "        train_specialist.layers.pop()\n",
    "        train_specialist.outputs = [train_specialist.layers[-1].output]\n",
    "        train_specialist.layers[-1].outbound_nodes = []\n",
    "        train_specialist.add(Dense(len(train_columns)))\n",
    "        \n",
    "        train_specialist.compile(loss='mean_squared_error', optimizer='adam')\n",
    "        change_lr = LearningRateScheduler(lambda epoch: float(learning_rate[epoch]))\n",
    "        early_stop = EarlyStopping(patience=100)\n",
    "        flipGen = FlippedImageDataGenerator()\n",
    "        \n",
    "        print(\"Entrenando modelo para las columnas {} por {} epochs\".format(train_columns, nb_epoch))\n",
    "        \n",
    "        train_specialist.fit_generator(flipGen.flow(X_train, y_train),\n",
    "                                steps_per_epoch=X_train.shape[0],\n",
    "                                epochs=nb_epoch,\n",
    "                                validation_data=(X_test, y_test),\n",
    "                                callbacks=[change_lr, early_stop])\n",
    "        \n",
    "        specialists[train_columns] = train_specialist "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo para las columnas ('left_eye_center_x', 'left_eye_center_y', 'right_eye_center_x', 'right_eye_center_y') por 100 epochs\n",
      "Epoch 1/100\n",
      "  32/5626 [..............................] - ETA: 5065s - loss: 32756948.0755"
     ]
    }
   ],
   "source": [
    "# Instanciamos modelo y corremos metodo de entrenamiento\n",
    "\n",
    "train_file = './data/training.csv'\n",
    "testing_file = './data/testing.csv'\n",
    "net = buildModel()\n",
    "fitTrainingSpecialists()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

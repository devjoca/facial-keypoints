{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from pandas.io.parsers import read_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Se definen los diccionarios de atributos que predeciran cada uno de los modelos que se implementaran\n",
    "\n",
    "training_specialists_settings = [\n",
    "    dict(\n",
    "        columns=(\n",
    "            'left_eye_center_x', 'left_eye_center_y',\n",
    "            'right_eye_center_x', 'right_eye_center_y',\n",
    "            ),\n",
    "        flip_indices=((0, 2), (1, 3)),\n",
    "        ),\n",
    "\n",
    "    dict(\n",
    "        columns=(\n",
    "            'nose_tip_x', 'nose_tip_y',\n",
    "            ),\n",
    "        flip_indices=(),\n",
    "        ),\n",
    "\n",
    "    dict(\n",
    "        columns=(\n",
    "            'mouth_left_corner_x', 'mouth_left_corner_y',\n",
    "            'mouth_right_corner_x', 'mouth_right_corner_y',\n",
    "            'mouth_center_top_lip_x', 'mouth_center_top_lip_y',\n",
    "            ),\n",
    "        flip_indices=((0, 2), (1, 3)),\n",
    "        ),\n",
    "\n",
    "    dict(\n",
    "        columns=(\n",
    "            'mouth_center_bottom_lip_x',\n",
    "            'mouth_center_bottom_lip_y',\n",
    "            ),\n",
    "        flip_indices=(),\n",
    "        ),\n",
    "\n",
    "    dict(\n",
    "        columns=(\n",
    "            'left_eye_inner_corner_x', 'left_eye_inner_corner_y',\n",
    "            'right_eye_inner_corner_x', 'right_eye_inner_corner_y',\n",
    "            'left_eye_outer_corner_x', 'left_eye_outer_corner_y',\n",
    "            'right_eye_outer_corner_x', 'right_eye_outer_corner_y',\n",
    "            ),\n",
    "        flip_indices=((0, 2), (1, 3), (4, 6), (5, 7)),\n",
    "        ),\n",
    "\n",
    "    dict(\n",
    "        columns=(\n",
    "            'left_eyebrow_inner_end_x', 'left_eyebrow_inner_end_y',\n",
    "            'right_eyebrow_inner_end_x', 'right_eyebrow_inner_end_y',\n",
    "            'left_eyebrow_outer_end_x', 'left_eyebrow_outer_end_y',\n",
    "            'right_eyebrow_outer_end_x', 'right_eyebrow_outer_end_y',\n",
    "            ),\n",
    "        flip_indices=((0, 2), (1, 3), (4, 6), (5, 7)),\n",
    "        ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Definimos metodo para cargar los archivos de entrenamiento para cada modelo a ser entrenado\n",
    "\n",
    "def loadTrainFile(cols=None):\n",
    "    df = read_csv(os.path.expanduser(train_file))\n",
    "    \n",
    "    # Es un solo campo separado por espacios hay que mostrarlo como array\n",
    "    df['Image'] = df['Image'].apply(lambda im: np.fromstring(im, sep=' '))\n",
    "    \n",
    "    # Filtramos los atributos especificos al modelo a ser entrenado\n",
    "    if cols:\n",
    "        df = df[list(cols) + ['Image']]\n",
    "        \n",
    "    # Eliminamos las entradas que no tienen todos los atributos especificados\n",
    "    df = df.dropna() \n",
    "    \n",
    "    # Escalar los pixeles entre 0 y 1\n",
    "    X = np.vstack(df['Image'].values) / 255. \n",
    "    X = X.astype(np.float32)\n",
    "    \n",
    "    y = df[df.columns[:-1]].values\n",
    "    y = (y - 48) / 48\n",
    "    X, y = shuffle(X, y, random_state=42)  # ordenar aleatoriamente la data de entrenamiento\n",
    "    y = y.astype(np.float32)\n",
    "    \n",
    "    # Escalar en 2 dimensiones, los pixeles son de 96 x 96\n",
    "    X = X.reshape(-1, 96, 96, 1)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# El tipo de red neuronal a implementar es LeNet-5  (http://yann.lecun.com/exdb/lenet/)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten, Dropout\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.callbacks import EarlyStopping, LearningRateScheduler\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def buildModel():\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    # Se agregan 3 capas convolucionales\n",
    "    model.add(Convolution2D(32,(3,3), input_shape=(96, 96, 1)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.1))\n",
    "    \n",
    "\n",
    "    model.add(Convolution2D(64, (2, 2)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Convolution2D(128, (2, 2)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    # Y dos capas densas\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1000))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1000))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(30))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Definimos metodo que usaremos para data augmentation, mediante el metodo de mirror image\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "class FlippedImageDataGenerator(ImageDataGenerator):\n",
    "    flip_indices = [(0, 2), (1, 3), (4, 8), (5, 9),\n",
    "                    (6, 10), (7, 11), (12, 16), (13, 17),\n",
    "                    (14, 18), (15, 19), (22, 24), (23, 25)]\n",
    "\n",
    "    def next(self):\n",
    "        X_batch, y_batch = super(FlippedImageDataGenerator, self).next()\n",
    "        batch_size = X_batch.shape[0]\n",
    "        indices = np.random.choice(batch_size, batch_size / 2, replace=False)\n",
    "        X_batch[indices] = X_batch[indices, :, :, ::-1]\n",
    "\n",
    "        if y_batch is not None:\n",
    "            y_batch[indices, ::2] = y_batch[indices, ::2] * -1\n",
    "\n",
    "            for a, b in self.flip_indices:\n",
    "                y_batch[indices, a], y_batch[indices, b] = (\n",
    "                    y_batch[indices, b], y_batch[indices, a]\n",
    "                )\n",
    "\n",
    "        return X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se define metodo que entrena los modelos especializados o training specialists\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import SGD\n",
    "from keras.models import model_from_json\n",
    "from collections import OrderedDict\n",
    "\n",
    "def fitTrainingSpecialists():\n",
    "    train_specialists = OrderedDict()\n",
    "    start = 0.03\n",
    "    stop = 0.001\n",
    "    nb_epoch = 100\n",
    "    learning_rate = np.linspace(start, stop, nb_epoch)\n",
    "    \n",
    "    for setting in training_specialists_settings:\n",
    "\n",
    "        # Se extraen las columnas especificas para cada modelo y se divide la data en set de entrenamiento\n",
    "        # y set de prueba\n",
    "        train_columns = setting['columns']\n",
    "        X, y = loadTrainFile(cols=train_columns)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        \n",
    "        # Se utiliza el modelo definido previamente\n",
    "        train_specialist = model_from_json(net.to_json())\n",
    "        \n",
    "        sgd = SGD(lr=start, momentum=0.9, nesterov=True)\n",
    "        train_specialist.compile(loss='mean_squared_error', optimizer=sgd)\n",
    "        change_lr = LearningRateScheduler(lambda epoch: float(learning_rate[epoch]))\n",
    "        early_stop = EarlyStopping(patience=100)\n",
    "        flipGen = FlippedImageDataGenerator()\n",
    "        \n",
    "        print(\"Entrenando modelo para las columnas {} por {} epochs\".format(train_columns, nb_epoch))\n",
    "        \n",
    "        hist = train_specialist.fit_generator(flipGen.flow(X_train, y_train),\n",
    "                                steps_per_epoch=X_train.shape[0],\n",
    "                                epochs=nb_epoch,\n",
    "                                validation_data=(X_test, y_test),\n",
    "                                callbacks=[change_lr, early_stop])\n",
    "        \n",
    "        specialists[train_columns] = train_specialist "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo para las columnas ('left_eye_center_x', 'left_eye_center_y', 'right_eye_center_x', 'right_eye_center_y') por 100 epochs\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected dense_27 to have shape (None, 30) but got array with shape (1407, 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-7ed5934561cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtesting_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./data/testing.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuildModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mfitTrainingSpecialists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-58-a6b212d404fb>\u001b[0m in \u001b[0;36mfitTrainingSpecialists\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m                                 \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                                 \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m                                 callbacks=[change_lr, early_stop])\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mspecialists\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_columns\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_specialist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, initial_epoch)\u001b[0m\n\u001b[1;32m   1119\u001b[0m                                         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1120\u001b[0m                                         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1976\u001b[0m                                  str(validation_data))\n\u001b[1;32m   1977\u001b[0m             val_x, val_y, val_sample_weights = self._standardize_user_data(\n\u001b[0;32m-> 1978\u001b[0;31m                 val_x, val_y, val_sample_weight)\n\u001b[0m\u001b[1;32m   1979\u001b[0m             \u001b[0mval_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_x\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mval_y\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mval_sample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1980\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muses_learning_phase\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[1;32m   1380\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1381\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m                                     exception_prefix='target')\n\u001b[0m\u001b[1;32m   1383\u001b[0m         sample_weights = _standardize_sample_weights(sample_weight,\n\u001b[1;32m   1384\u001b[0m                                                      self._feed_output_names)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    142\u001b[0m                             \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                             \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m                             str(array.shape))\n\u001b[0m\u001b[1;32m    145\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected dense_27 to have shape (None, 30) but got array with shape (1407, 4)"
     ]
    }
   ],
   "source": [
    "# Instanciamos modelo y corremos metodo de entrenamiento\n",
    "\n",
    "train_file = './data/training.csv'\n",
    "testing_file = './data/testing.csv'\n",
    "net = buildModel()\n",
    "fitTrainingSpecialists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
